# Assessment of Impact

## Introduction
This section discusses the assessment of repositories' impact on users. While this is usually the connotation of the word "assessment" when it's used in a library context, it should be noted that there are many other aspects of repositories that should be assessed and evaluated, including:

Curation
Metadata
Software infrastructure
Documentation
Preservation
`links needed above`

Please follow the links above to other sections of this handbook, where the appropriate methods of assessment are discussed.

Similarly, while the connotation of the term "user" is often "end user," this section does not speak exclusively to that cohort. The practices detailed can also be applied to other user groups; for example, unit librarians responsible for recruiting content into a repository (see: http://blogs.cornell.edu/dsps/2017/10/30/scwg-ecommons-and-unit-libraries/).

Repository managers can assess the impact of repositories in a number of ways depending on the primary goals of the project, current concerns, and research questions. Assessment results can be used as evidence of success, for outreach, publicity efforts, reporting, improvement of service, or for internal evaluations of workflows. Visualizations of that data such as maps, graphs of trends, or even interactive tools can enhance those efforts by facilitating stronger narratives.

Developing an assessment plan should not wait until stakeholders ask you for this information. Fortunately, Library Assessment & Communication can help you think through your needs and appropriate approaches, and can be reached at `need e-mail address`.

### Content in this section:
[Usage statistics](#usage-statistics)
[Impact stories](#impact-stories)
[User satisfaction](#user-satisfaction)
[Usability](#usability)

## Usage statistics
`this section will need major updates`
Depending on the purpose of your repository, there may be different types of use -- and therefore, different kinds of usage statistics -- that you will want to track. While this section largely focuses on repositories with a strong dissemination function, a repository whose purpose is primarily preservation (for example) will likely measure its impact in different ways. Be sure to identify the use that is most important to assessing your impact, and pursue statistics appropriately.

If your repository does serve a dissemination function, then its software should be able to provide information on how many items have been added to the repository, as well as how many times items in the repository have been downloaded (or otherwise accessed), and the Repository Service Owner and Repository Service Manager should familiarize themselves with how to access and report on this data. The decision of whether or not to include unintentional or automated uses (e.g. double-clicking or access by robots) may vary. Whatever the decision, it is best practice to publicly document how your repository addresses (or is unable to address) such common data issues.

Beyond the reporting features of the native systems, third party analytics applications can also be used to collect usage statistics for public-facing websites, including repositories. CULIT maintains a central instance of Piwik which can be used for this purpose; to get started with Piwik for your repository, contact library-systems@cornell.edu. For assistance in reading your reports, contact libraryux@cornell.edu.

Assessment and Communication collects certain usage statistics annually, and reports them out to national agencies; items held and download counts for institutional repositories are currently reported to ACRL, for example. Cornell University Library also uses these figures for internal trend tracking: see the collections and collections use table of the CUL Statistical Trends report.

Both native and third-party systems can track other sorts of use information which may prove helpful to your assessment efforts: e.g. where users get referred from, usersâ€™ domains and geographic locations, Cornell vs. non-Cornell use, and unique user data that allows for calculation of the percentage of a user population uploading material, etc. Some systems also track downloads to the article or collection level. These data might be useful to answering specific questions, so it's important to talk with your stakeholders to identify their needs. While these data are not generally collected by Library Assessment & Communication, they may contact you if the needs are identified on their ends.

Usage data collection also raises questions of user privacy. Legally and ethically, we cannot share personally identifiable information about how any individual patron uses our collections, therefore we must be vigilant about anonymizing the data and about our processes and assessment methods that could lead to the identification of a patron's use of our materials, deliberately or inadvertently. It is possible for the combination of data from multiple sources to identify a specific patron's activities, even if individual data sources cannot do this alone. Be sure to work with Library Assessment & Communication, CULIT, and the Director of Copyright as appropriate to make sure that your methods adhere to our policies and the law.

- [ ] Identify the kind of usage statistics that best reflect the impact of your repository.
- [ ] Identify and familiarize yourself with the native use assessment systems of the repository software you are using, or considering using, to ensure that you are able to access the usage statistics you've identified as important.
  - [ ] If appropriate, determine whether and/or how to track unintentional or automatic usage, and document your decision.
- [ ] Consult with CULIT to identify and familiarize yourself with any third-party systems in use at CUL that might also be implemented to assess repository use.
- [ ] Contact Library Assessment & Communications regarding their recurrent usage data needs.
- [ ] Identify and consult with other stakeholders with whom you will share usage data.
- [ ] Consult with Library Assessment & Communications about other forms of data collection, as well as CULIT and the Director of Copyright as appropriate to ensure adherence to policies and laws.
- [ ] Familiarize yourself with the privacy and confidentiality policies of the Library.
[Return to top](#top)

## Impact stories
Impact stories relate how the broader visibility of material in your repository influenced your users, through events such as serendipitous discoveries, new partnerships, or career opportunities. These stories are the step beyond usage stats, tracing not just how often patrons access material, but how that material changes and shapes them, and how it is shaped by them in turn. This demonstrates the value of the repository in a more resonant way.

Impact stories can come to you unsolicited from satisfied patrons, so you'll need to work with the patrons to determine whether the stories can be shared publicly, and under what restrictions (e.g. anonymity). Library Assessment & Communication can help you find ways to leverage shareable stories for broader publicity, as well as solicit stories more systematically through qualitative studies.

While we cannot (and should not) track any individual patron's use of our repositories, the stories our patrons are willing to share can help define the value of our repositories.

- [ ] Track user stories that come to you unsolicited.
- [ ] Identify patrons who may have good stories to tell.
- [ ] Confirm your patrons' permission to share their stories and be publicly quoted
- [ ] Pass quotes on to Library Assessment & Communication at libcomm@cornell.edu who maintain a database of testimonials and can consult on publicity.
- [ ] Consult with Library Assessment & Communication about qualitative user studies.
[Return to top](#top)

## User satisfaction
User satisfaction can be assessed on either a cyclical or an ad hoc basis, depending on your resources and needs. The most common means of assessing user satisfaction is via surveys, which can be disseminated on the system itself to reach users directly, or through email or other outreach means. The latter has the benefit of potentially interacting with non-users as well, and determining why they are not accessing the repository.

Use of repositories has been included in broad-based CUL user surveys, for example frequency of repository use in the 2016 graduate student survey. Contact Library Assessment & Communication to find out what such surveys can tell you about repositories, or how to best create and deploy a survey customized to your needs.

- [ ] Determine whether cyclical or ad hoc user satisfaction surveys meet the needs of your repository service.
- [ ] If cyclical, establish your assessment schedule.
  - [ ] Contact Library Assessment & Communication to see if any existing survey results contain relevant information.
  - [ ] Contact Library Assessment & Communication to see if any of their cyclical surveys can be expanded to include questions about your repository.
  - [ ] Contact Library Assessment & Communications for a consultation on creating and deploying a customized user satisfaction survey.
[Return to top](#top)

## Usability
Usability testing assesses how well the system interface of your repository and the organization of its content work in terms of ease and intuitiveness of use. This process is described in more detail in the [Access: Discovery and Delivery](/Access-Discover-and-Delivery) section of this handbook.

[Return to top](#top)
